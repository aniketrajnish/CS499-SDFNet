{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iteration1_bottles.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketrajnish/CS499-SDFNet/blob/main/Iteration1_bottles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/\n",
        "https://www.projectpro.io/recipes/crop-and-resize-image-pytorch\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
      ],
      "metadata": {
        "id": "GOqyi5esHyLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UOKl-c5YM54",
        "outputId": "72a06821-babd-4785-f613-72dfa88320fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX_5UX5U6347"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import tensorflow.keras as keras\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/drive/MyDrive/GraphicsModelRendering/BottleRenders_New.zip' -d '/content/sample_data/new'"
      ],
      "metadata": {
        "id": "DWWbFgPAZu51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = '/content/drive/MyDrive/GraphicsModelRendering/BottleVars.csv'\n",
        "\n",
        "train_folder = '/content/drive/MyDrive/GraphicsModelRendering/BottleRenders'"
      ],
      "metadata": {
        "id": "Ydf0E53e70kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df['combined'] = np.asarray(train_df[train_df.columns[1:]].values)"
      ],
      "metadata": {
        "id": "vgnh6Tp_8FEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df = train_df.filter(['Bottle', 'combined'])\n"
      ],
      "metadata": {
        "id": "E8E-PldD86nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_gen = ImageDataGenerator(rescale=1./255)\n",
        "# train_data = train_gen.flow_from_dataframe(dataframe=train_df, directory=train_folder, x_col='Bottle',\n",
        "#                                            y_col='combined', batch_size=16, shuffle=True,\n",
        "#                                            class_mode='raw', target_size=(200, 150))"
      ],
      "metadata": {
        "id": "Ve_N9JOQ9dBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from skimage import io, transform\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "wO9PaeSO_tD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size. Smaller image side is mathced to a given integer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, labels = sample[0], sample[1]\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "\n",
        "        return img,labels\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, labels = sample[0], sample[1]\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return torch.from_numpy(image), torch.from_numpy(labels)"
      ],
      "metadata": {
        "id": "AMypbRXdy7le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        im=Image.open(img_path)\n",
        "        im=im.convert('RGB')\n",
        "        image = np.asarray(im)\n",
        "        labels = self.img_labels.iloc[idx, 1:]\n",
        "        labels = np.asarray([labels])\n",
        "        labels = labels.astype('float')\n",
        "        sample=(image,labels)\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample"
      ],
      "metadata": {
        "id": "yO7xIzK9BUSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhQ8X_CuE5Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomImageDataset(train_file,\n",
        "                                         train_folder,\n",
        "                                         transforms.Compose([Rescale(300),ToTensor()]))"
      ],
      "metadata": {
        "id": "Gzm-5G_vIi7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_uZ_TSjNK91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "validation_split = .05\n",
        "shuffle_dataset = False\n",
        "random_seed= 42\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "trainSteps = len(train_loader.dataset) // batch_size\n",
        "valSteps = len(validation_loader.dataset) // batch_size\n"
      ],
      "metadata": {
        "id": "stYaryJLQSid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "zO_S80u4RuEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GU1RaMVWSTES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Model(Module):\n",
        "  def __init__(self, numChannels, num_classes):\n",
        "\t\t# call the parent constructor\n",
        "    super(My_LeNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "            nn.Conv2d(numChannels, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.dense = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(256 * 6 * 6, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(2048, num_classes),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.dense(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "XCAZwuiISyPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OUgpmowzHwUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = My_Model(\n",
        "\tnumChannels=3,\n",
        "\tnum_classes=19).to(device)"
      ],
      "metadata": {
        "id": "s9X06Hr3VJVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-3\n",
        "opt = Adam(model.parameters(), lr=INIT_LR)\n",
        "lossFn = torch.nn.L1Loss()"
      ],
      "metadata": {
        "id": "cLFuTYGxVrLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = {\n",
        "\t\"train_loss\": [],\n",
        "\t\"val_loss\": [],\n",
        "}\n"
      ],
      "metadata": {
        "id": "o6947BQBWsAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=8\n",
        "startTime = time.time()\n",
        "def my_loss(output, target):\n",
        "    loss = torch.mean(abs((output - target)/output))\n",
        "    return loss\n",
        "for e in range(0, EPOCHS):\n",
        "  # set the model in training mode\n",
        "  model.train()\n",
        "  # initialize the total training and validation loss\n",
        "  totalTrainLoss = 0\n",
        "  totalValLoss = 0\n",
        "  # initialize the number of correct predictions in the training\n",
        "  # and validation step\n",
        "  trainCorrect = 0\n",
        "  valCorrect = 0\n",
        "\t# loop over the training set\n",
        "  \n",
        "  loss=torch.zeros([1], dtype=torch.float32, device=device)\n",
        "  for (x, y) in train_loader:\n",
        "    # send the input to the device\n",
        "    (x, y) = (x.to(device), y.to(device))\n",
        "    # perform a forward pass and calculate the training loss\n",
        "    x=x.type(torch.float)\n",
        "    y=y.type(torch.float)\n",
        "    pred = model(x)\n",
        "    loss=my_loss(pred,y)\n",
        "    # zero out the gradients, perform the backpropagation step,\n",
        "    # and update the weights\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    # add the loss to the total training loss so far and\n",
        "    # calculate the number of correct predictions\n",
        "    totalTrainLoss += loss\n",
        "    \n",
        "  with torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "    model.eval()\n",
        "    # loop over the validation set\n",
        "    for (x, y) in validation_loader:\n",
        "      # send the input to the device\n",
        "      \n",
        "      (x, y) = (x.to(device), y.to(device))\n",
        "      # make the predictions and calculate the validation loss\n",
        "      x=x.type(torch.float)\n",
        "      pred = model(x)\n",
        "      print(pred)\n",
        "      totalValLoss += (lossFn(pred, y)*19)\n",
        "      \n",
        "  avgTrainLoss = totalTrainLoss / trainSteps\n",
        "  avgValLoss = totalValLoss / valSteps\n",
        "\t# calculate the training and validation accuracy\n",
        "  trainCorrect = trainCorrect / len(train_loader.dataset)\n",
        "  valCorrect = valCorrect / len(validation_loader.dataset)\n",
        "  # update our training history\n",
        "  H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "  H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "  # print the model training and validation information\n",
        "  print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
        "\n",
        "endTime = time.time()"
      ],
      "metadata": {
        "id": "Z1bN8ng2W-1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "#plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
        "\n",
        "plt.title(\"Training Loss on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0SatcTQEbEqt",
        "outputId": "84d44fd0-e953-474e-e4ae-a6bd219dabbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.transforms.functional as fn\n",
        "# img_path='/content/drive/MyDrive/GraphicsModelRendering/BottleRenders/Bottle1.png'\n",
        "# im=Image.open(img_path)\n",
        "# im=im.convert('RGB')\n",
        "# width, height = im.size\n",
        "# im.show()\n",
        "# # Setting the points for cropped image\n",
        "# left = 320\n",
        "# top = 0\n",
        "# right = 560\n",
        "# bottom = 2.6 * height / 4\n",
        " \n",
        "# # Cropped image of above dimension\n",
        "# # (It will not change original image)\n",
        "# im1 = im.crop((left, top, right, bottom))\n",
        " \n",
        "# # Shows the image in image viewer\n",
        "# im1.show()\n"
      ],
      "metadata": {
        "id": "J7B2I0-q8dSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_dataset = CustomImageDataset(test_file,\n",
        "#                                          test_folder,\n",
        "#                                          transforms.Compose([Rescale(150),ToTensor()]))"
      ],
      "metadata": {
        "id": "CybEWCkIC7x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/GraphicsModelRendering/alexnet_new.h5')"
      ],
      "metadata": {
        "id": "dmVFM4R6C97C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ZpOeYLeDe1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJn_wmRktgxj",
        "outputId": "9255ada1-af13-4b62-b844-a45af7ee4fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}